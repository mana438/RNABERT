{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Description\n",
    "Welcome to Stanford Ribonanza RNA Folding challenge. The task of this competition is predicting the chemical reactivity at each position of an RNA molecule. These data are extremely sensitive to the structure that each RNA forms, and an algorithm that could perfectly predict these chemical reactivities would need to have an implicit ‘understanding’ of RNA structure. Such an oracle could be then utilized to predictively model structures of novel RNA molecules. A better understanding of how to manipulate RNA could help usher in an age of programmable medicine, including first cures for pancreatic cancer and Alzheimer’s disease as well as much-needed antibiotics and new biotechnology approaches for climate change. \n",
    "\n",
    "This notebook provides a simple baseline that may be used as a starting point for further experiments. Improvment of the baseline may include: \n",
    "1. Use of proper loss function to incorporate SN_filter = 0 samples as well as reactivity errors into training\n",
    "2. Model improvement and use of additional data, e.g. Ribonanza_bpp_files\n",
    "\n",
    "Finally, working on this competition keep in mind that train/public LB have different sequence length distribution from private LB, i.e. 115-206 vs. 207-457. Therefore, to avoid a strong shakeup one may need to look into performance vs. sequence length end ensure generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/Horikitasaku/RNA-FM.git\n",
    "# import os\n",
    "# os.chdir('/kaggle/working/RNA-FM/')\n",
    "# !pip install .\n",
    "# !mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "# !cp /kaggle/input/h-one-for-all-model/RNA-FM_pretrained.pth /root/.cache/torch/hub/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/Horikitasaku/RNABERT.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fm\n",
    "\n",
    "backbone, alphabet = fm.pretrained.rna_fm_t12()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "# model.eval()  # disables dropout for deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, gc\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./RNABERT')\n",
    "from utils.bert import Load_RNABert_Model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "---Loaded---\n"
     ]
    }
   ],
   "source": [
    "BERTmodel = Load_RNABert_Model('RNABERT/RNABERT.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(6, 120, padding_idx=0)\n",
       "      (position_embeddings): Embedding(440, 120)\n",
       "      (token_type_embeddings): Embedding(2, 120)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (selfattn): BertSelfAttention(\n",
       "              (query): Linear(in_features=120, out_features=120, bias=True)\n",
       "              (key): Linear(in_features=120, out_features=120, bias=True)\n",
       "              (value): Linear(in_features=120, out_features=120, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=120, out_features=120, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=120, out_features=40, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=40, out_features=120, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=120, out_features=120, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): MaskedWordPredictions(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "      )\n",
       "      (decoder): Linear(in_features=120, out_features=6, bias=False)\n",
       "    )\n",
       "    (predictions_ss): MaskedWordPredictions(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "      )\n",
       "      (decoder): Linear(in_features=120, out_features=8, bias=False)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=120, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERTmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix fastai bug to enable fp16 training with dictionaries\n",
    "\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "def flatten(o):\n",
    "    \"Concatenate all collections and items as a generator\"\n",
    "    for item in o:\n",
    "        if isinstance(o, dict): yield o[item]; continue\n",
    "        elif isinstance(item, str): yield item; continue\n",
    "        try: yield from flatten(item)\n",
    "        except TypeError: yield item\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "@delegates(GradScaler)\n",
    "class MixedPrecision(Callback):\n",
    "    \"Mixed precision training using Pytorch's `autocast` and `GradScaler`\"\n",
    "    order = 10\n",
    "    def __init__(self, **kwargs): self.kwargs = kwargs\n",
    "    def before_fit(self): \n",
    "        self.autocast,self.learn.scaler,self.scales = autocast(),GradScaler(**self.kwargs),L()\n",
    "    def before_batch(self): self.autocast.__enter__()\n",
    "    def after_pred(self):\n",
    "        if next(flatten(self.pred)).dtype==torch.float16: self.learn.pred = to_float(self.pred)\n",
    "    def after_loss(self): self.autocast.__exit__(None, None, None)\n",
    "    def before_backward(self): self.learn.loss_grad = self.scaler.scale(self.loss_grad)\n",
    "    def before_step(self):\n",
    "        \"Use `self` as a fake optimizer. `self.skipped` will be set to True `after_step` if gradients overflow. \"\n",
    "        self.skipped=True\n",
    "        self.scaler.step(self)\n",
    "        if self.skipped: raise CancelStepException()\n",
    "        self.scales.append(self.scaler.get_scale())\n",
    "    def after_step(self): self.learn.scaler.update()\n",
    "\n",
    "    @property \n",
    "    def param_groups(self): \n",
    "        \"Pretend to be an optimizer for `GradScaler`\"\n",
    "        return self.opt.param_groups\n",
    "    def step(self, *args, **kwargs): \n",
    "        \"Fake optimizer step to detect whether this batch was skipped from `GradScaler`\"\n",
    "        self.skipped=False\n",
    "    def after_fit(self): self.autocast,self.learn.scaler,self.scales = None,None,None\n",
    "        \n",
    "import fastai\n",
    "fastai.callback.fp16.MixedPrecision = MixedPrecision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNABertModel(\n",
       "  (embed_tokens): Embedding(25, 640, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (v_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (q_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=640, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=640, bias=True)\n",
       "      (final_layer_norm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=240, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (embed_positions): LearnedPositionalEmbedding(1026, 640, padding_idx=1)\n",
       "  (emb_layer_norm_before): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "  (emb_layer_norm_after): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=640, out_features=640, bias=True)\n",
       "    (layer_norm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'RNA-FM-EM-TRANS'\n",
    "PATH = './stanford-ribonanza-rna-folding-converted'\n",
    "OUT = './'\n",
    "bs = 64\n",
    "num_workers = 90\n",
    "SEED = 2023\n",
    "nfolds = 4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The primary training data is provided in train_data.csv, which contains 821840 RNA sequences and the corresponding reactivity measurements with 2A3_MaP and DMS_MaP methods. The reactivity is reported in columns reactivity_0001 - reactivity_0206 and is set to NaN for the first 26 and the last 21 nucleotides as well as padding for sequences shorter than 206. For faster loading and effective RAM use, I converted the data into a float32 parquet file. \n",
    "\n",
    "Evaluation in this competition is performed only on samples with SN_filter = 1 for both measurement methods. In this example, I perform training only on samples wiht SN_filter = 1, which gives a noticeable CV boost but uses only 1/4 of the data (i.e. training on noisy SN_filter = 0 data degrades the performance). A proper consideration of all data as well as reactivity errors may boost the performance.\n",
    "\n",
    "In this example, I use a simple CV Kfold split. However, given a mismatch in the RNA length between train/public LB vs. private LB data, **it may be important to verify the effect of the sequence length** to avoid a significant shakeup at the private LB.\n",
    "\n",
    "One of the tricks, well known in NLP community, which I use here, is length matching batch sampling: composing batches of samples of approximately the same length to minimize the overhead caused by padding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_token_batch(alphabet, seq_strs):\n",
    "    batch_size = len(seq_strs)\n",
    "#     max_len = 206\n",
    "    max_len = max(len(seq_str) for seq_str in seq_strs)\n",
    "    tokens = torch.empty(\n",
    "        (\n",
    "            batch_size,\n",
    "            max_len\n",
    "            + int(alphabet.prepend_bos)\n",
    "            + int(alphabet.append_eos),\n",
    "        ),\n",
    "        dtype=torch.int64,\n",
    "    )\n",
    "    tokens.fill_(alphabet.padding_idx)\n",
    "    for i, seq_str in enumerate(seq_strs):              \n",
    "        if alphabet.prepend_bos:\n",
    "            tokens[i, 0] = alphabet.cls_idx\n",
    "        seq = torch.tensor([alphabet.get_idx(s) for s in seq_str], dtype=torch.int64)\n",
    "        tokens[i, int(alphabet.prepend_bos): len(seq_str)+ int(alphabet.prepend_bos),] = seq\n",
    "        if alphabet.append_eos:\n",
    "            tokens[i, len(seq_str) + int(alphabet.prepend_bos)] = alphabet.eos_idx\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNA_Dataset(Dataset):\n",
    "    def __init__(self, df, mode='train', seed=2023, fold=0, nfolds=4, \n",
    "                 mask_only=False, **kwargs):\n",
    "        self.seq_map = {'A':0,'C':1,'G':2,'U':3}\n",
    "        self.Lmax = 206\n",
    "        df['L'] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type=='2A3_MaP']\n",
    "        df_DMS = df.loc[df.experiment_type=='DMS_MaP']\n",
    "        \n",
    "        split = list(KFold(n_splits=nfolds, random_state=seed, \n",
    "                shuffle=True).split(df_2A3))[fold][0 if mode=='train' else 1]\n",
    "        df_2A3 = df_2A3.iloc[split].reset_index(drop=True)\n",
    "        df_DMS = df_DMS.iloc[split].reset_index(drop=True)\n",
    "        \n",
    "        m = (df_2A3['SN_filter'].values > 0) & (df_DMS['SN_filter'].values > 0)\n",
    "        df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "        df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "        \n",
    "        self.seq = df_2A3['sequence'].values\n",
    "        self.L = df_2A3['L'].values\n",
    "        \n",
    "        self.react_2A3 = df_2A3[[c for c in df_2A3.columns if \\\n",
    "                                 'reactivity_0' in c]].values\n",
    "        self.react_DMS = df_DMS[[c for c in df_DMS.columns if \\\n",
    "                                 'reactivity_0' in c]].values\n",
    "        self.react_err_2A3 = df_2A3[[c for c in df_2A3.columns if \\\n",
    "                                 'reactivity_error_0' in c]].values\n",
    "        self.react_err_DMS = df_DMS[[c for c in df_DMS.columns if \\\n",
    "                                'reactivity_error_0' in c]].values\n",
    "        self.sn_2A3 = df_2A3['signal_to_noise'].values\n",
    "        self.sn_DMS = df_DMS['signal_to_noise'].values\n",
    "        self.mask_only = mask_only\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.seq)  \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        tokens = seq\n",
    "        records = BERTmodel.load_data_EMB(tokens)\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[:len(seq)] = True\n",
    "            return {'mask':mask},{'mask':mask}\n",
    "        \n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "#         print(seq)\n",
    "#         tokens = generate_token_batch(alphabet,[tokens])\n",
    "#         seq = np.array(seq)\n",
    "#         with torch.no_grad():\n",
    "#             results = backbone(tokens, repr_layers=[12], need_head_weights=False,return_contacts=False)\n",
    "#             token_embeddings = results[\"representations\"][12]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:len(seq)] = True\n",
    "        seq = np.pad(seq,(0,self.Lmax-len(seq)))\n",
    "        \n",
    "        react = torch.from_numpy(np.stack([self.react_2A3[idx],\n",
    "                                           self.react_DMS[idx]],-1))\n",
    "        # print(react.shape)\n",
    "        react_err = torch.from_numpy(np.stack([self.react_err_2A3[idx],\n",
    "                                               self.react_err_DMS[idx]],-1))\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx],self.sn_DMS[idx]])\n",
    "        return {'seq':torch.from_numpy(seq),'tokens': tokens,'mask':mask, 'records': records[1]}, \\\n",
    "               {'react':react, 'react_err':react_err,\n",
    "                'sn':sn, 'mask':mask}\n",
    "    \n",
    "class LenMatchBatchSampler(torch.utils.data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            s = self.sampler.data_source[idx]\n",
    "            if isinstance(s,tuple): L = s[0][\"mask\"].sum()\n",
    "            else: L = s[\"mask\"].sum()\n",
    "            L = max(1,L // 16) \n",
    "            if len(buckets[L]) == 0:  buckets[L] = []\n",
    "            buckets[L].append(idx)\n",
    "            \n",
    "            if len(buckets[L]) == self.batch_size:\n",
    "                batch = list(buckets[L])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[L] = []\n",
    "                \n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "            \n",
    "def dict_to(x, device='cuda'):\n",
    "    return {k:x[k].to(device) for k in x}\n",
    "\n",
    "def to_device(x, device='cuda'):\n",
    "    return tuple(dict_to(e,device) for e in x)\n",
    "\n",
    "class DeviceDataLoader:\n",
    "    def __init__(self, dataloader, device='cuda'):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dataloader:\n",
    "            # for each batch\n",
    "            batch[0]['tokens'] = generate_token_batch(alphabet,batch[0]['tokens'])\n",
    "            \n",
    "\n",
    "            yield tuple(dict_to(x, self.device) for x in batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Transformers are ideal for the considered task because they naturally capture long dependences in RNN, which define the secondary structure of the molecule and the corresponding chemical reactivity. For illustration purposes, below I provide a simple S-size transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim=64, M=10000000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.M = M\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.M) / half_dim\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * (-emb))\n",
    "        emb = x[...,None] * emb[None,...]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        \n",
    "#         emb = emb.unsqueeze(1) + x.unsqueeze(0)\n",
    "        return emb\n",
    "\n",
    "class ShapeEmb(nn.Module):\n",
    "    def __init__(self, dim=192):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        _, sequence_length = x.size()\n",
    "        emb = torch.zeros(sequence_length, self.dim, device=x.device)\n",
    "        return emb\n",
    "\n",
    "class Pos_emb(nn.Module):\n",
    "    def __init__(self, max_position_embeddings, hidden_size=512):\n",
    "        super().__init__()\n",
    "        self.position_embeddings = nn.Embedding(max_position_embeddings, hidden_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        pos_emb = self.position_embeddings(x)\n",
    "        return pos_emb\n",
    "\n",
    "class RNA_Model(nn.Module):\n",
    "    def __init__(self, dim=512, depth=12, head_size=32, **kwargs):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(4,dim)\n",
    "        self.BERTmodel = Load_RNABert_Model('RNABERT/RNABERT.pth')\n",
    "        self.pos_enc = Pos_emb(max_position_embeddings = dim)\n",
    "        # self.lstm = nn.RNN(input_size=dim, hidden_size=512, batch_first=True, bidirectional=True)\n",
    "        # self.embedding_layer_norm = nn.LayerNorm(dim)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=dim, nhead=dim//head_size, dim_feedforward=4*dim,\n",
    "                dropout=0.1, activation=nn.GELU(), batch_first=True, norm_first=True), depth)\n",
    "        self.proj_out = nn.Sequential(\n",
    "                nn.Linear(dim,dim),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(dim,2),\n",
    "            )\n",
    "    \n",
    "    def forward(self, x0):\n",
    "        mask = x0['mask']\n",
    "        records = x0['records']\n",
    "        Lmax = mask.sum(-1).max()\n",
    "        mask = mask[:,:Lmax]\n",
    "        x = x0['seq'][:,:Lmax]\n",
    "        bert_emb = self.BERTmodel.predict_by_tokens(Lmax,records)\n",
    "        pos = torch.arange(Lmax, device=x.device).unsqueeze(0)\n",
    "        pos = self.pos_enc(pos)\n",
    "#         print(pos.shape)\n",
    "#         print(x.shape)\n",
    "\n",
    "        x = self.emb(x)\n",
    "        x = x + bert_emb + pos\n",
    "        # x = self.embedding_layer_norm(x)\n",
    "        x = self.transformer(x, src_key_padding_mask=~mask)\n",
    "        \n",
    "        # x, _ = self.lstm(x)\n",
    "\n",
    "        x = self.proj_out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class RNA_embedding_model(nn.Module):\n",
    "    def __init__(self, dim=64, depth=12, head_size=32, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.emb = nn.Embedding(4,dim)\n",
    "        # self.pos_enc = SinusoidalPosEmb(dim)\n",
    "        self.transformer1 = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=dim, nhead=dim//head_size, dim_feedforward=4*dim,\n",
    "                dropout=0.1, activation=nn.GELU(), batch_first=True, norm_first=True), 6)\n",
    "\n",
    "    def forward(self, x0):\n",
    "\n",
    "        x = self.transformer1(x0.squeeze(0))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human5PrimeUTRPredictor(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    contact predictor with inner product\n",
    "    \"\"\"\n",
    "    def __init__(self, alphabet=None, task=\"rgs\", arch=\"cnn\", input_types=[\"seq\", \"emb-rnafm\"]):\n",
    "        \"\"\"\n",
    "        :param depth_reduction: mean, first\n",
    "        \"\"\"       \n",
    "        super().__init__()     \n",
    "        self.alphabet = alphabet   # backbone alphabet: pad_idx=1, eos_idx=2, append_eos=True, prepend_bos=True\n",
    "        self.task = task\n",
    "        self.arch = arch\n",
    "        self.input_types = input_types        \n",
    "        self.padding_mode = \"right\"\n",
    "        self.token_len = 500\n",
    "        self.out_plane = 2\n",
    "        self.in_channels = 0\n",
    "        self.main_planes = 640\n",
    "        dim=512\n",
    "        depth=12 \n",
    "        head_size=32\n",
    "        if \"seq\" in self.input_types:\n",
    "            self.in_channels = self.in_channels + 4\n",
    "\n",
    "        if \"emb-rnafm\" in self.input_types:\n",
    "            self.reductio_module = nn.Linear(640, 512)\n",
    "            self.in_channels = self.in_channels + 512  \n",
    "\n",
    "        if self.arch == \"cnn\" and self.in_channels != 0:\n",
    "            # self.predictor = self.create_1dcnn_for_emd(in_planes=self.in_channels, out_planes= self.out_plane)\n",
    "            ...\n",
    "        else:\n",
    "            raise Exception(\"Wrong Arch Type\")\n",
    "        # self.RNA_linear = RNA_Model()\n",
    "        self.RNA_embed = RNA_embedding_model(dim = dim)\n",
    "        self.backbone, self.alphabet = fm.pretrained.rna_fm_t12()\n",
    "        self.pos_out = nn.Sequential(\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Linear(128, 2),\n",
    "        )\n",
    "        self.pos_enc = Pos_emb(max_position_embeddings = dim)\n",
    "    def forward(self, x):\n",
    "        tokens = x['tokens'].squeeze(1)\n",
    "#         print(tokens.shape)\n",
    "        seq_len = tokens.shape[1]-2\n",
    "        # self.pos_enc = Pos_Encoder(seq_len = seq_len, dim = self.main_planes)\n",
    "        # self.pos_enc = Shape_Encoder(seq_len = seq_len, dim = self.main_planes)\n",
    "        # Base_RNA = self.RNA_linear(x)\n",
    "#         print(tokens.shape)\n",
    "        # with torch.no_grad():\n",
    "        results = backbone(tokens, repr_layers=[12], need_head_weights=False,return_contacts=False)\n",
    "        inputs = results[\"representations\"][12]\n",
    "        ensemble_inputs = []\n",
    "        if \"seq\" in self.input_types:\n",
    "            # padding one-hot embedding            \n",
    "            nest_tokens = (tokens[:, 1:-1] - 4)   # covert token for RNA-FM (20 tokens) to nest version (4 tokens A,U,C,G)\n",
    "            nest_tokens = torch.nn.functional.pad(nest_tokens, (0, self.token_len - nest_tokens.shape[1]), value=-2)\n",
    "            token_padding_mask = nest_tokens.ge(0).long()\n",
    "            one_hot_tokens = torch.nn.functional.one_hot((nest_tokens * token_padding_mask), num_classes=4)\n",
    "            one_hot_tokens = one_hot_tokens.float() * token_padding_mask.unsqueeze(-1)            \n",
    "            # reserve padded one-hot embedding\n",
    "            one_hot_tokens = one_hot_tokens.permute(0, 2, 1)  # B, L, 4\n",
    "            ensemble_inputs.append(one_hot_tokens)\n",
    "\n",
    "        if \"emb-rnafm\" in self.input_types:\n",
    "            embeddings = inputs\n",
    "            # padding RNA-FM embedding\n",
    "            embeddings, padding_masks = self.remove_pend_tokens_1d(tokens, embeddings)  # remove auxiliary tokens\n",
    "            embeddings = embeddings.squeeze(dim=1)\n",
    "            batch_size, seqlen, hiddendim = embeddings.size()\n",
    "            \n",
    "            # embeddings = torch.nn.functional.pad(embeddings, (0, 0, 0, self.token_len - embeddings.shape[1]))            \n",
    "            # # channel reduction\n",
    "            embeddings = self.reductio_module(embeddings)\n",
    "            # # reserve padded RNA-FM embedding\n",
    "            # embeddings = embeddings.permute(0, 2, 1)\n",
    "            ensemble_inputs.append(embeddings)        \n",
    "\n",
    "        ensemble_inputs = torch.cat(ensemble_inputs, dim=1)  \n",
    "        \n",
    "\n",
    "        output = self.pos_out(ensemble_inputs).squeeze(0)\n",
    "        return output\n",
    " \n",
    "    def create_1dcnn_for_emd(self, in_planes, out_planes):\n",
    "        main_planes = self.main_planes\n",
    "        dropout = 0.2\n",
    "        emb_cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_planes, main_planes, kernel_size=3, padding=1), \n",
    "            ResBlock(main_planes * 1, main_planes * 1, stride=2, dilation=1, conv_layer=nn.Conv1d,\n",
    "                     norm_layer=nn.BatchNorm1d), \n",
    "            ResBlock(main_planes * 1, main_planes * 1, stride=1, dilation=1, conv_layer=nn.Conv1d,\n",
    "                     norm_layer=nn.BatchNorm1d),  \n",
    "            ResBlock(main_planes * 1, main_planes * 1, stride=2, dilation=1, conv_layer=nn.Conv1d,\n",
    "                     norm_layer=nn.BatchNorm1d), \n",
    "            ResBlock(main_planes * 1, main_planes * 1, stride=1, dilation=1, conv_layer=nn.Conv1d,\n",
    "                     norm_layer=nn.BatchNorm1d),  \n",
    "            ResBlock(main_planes * 1, main_planes * 1, stride=2, dilation=1, conv_layer=nn.Conv1d,\n",
    "                     norm_layer=nn.BatchNorm1d), \n",
    "            ResBlock(main_planes * 1, main_planes * 1, stride=1, dilation=1, conv_layer=nn.Conv1d,\n",
    "                     norm_layer=nn.BatchNorm1d),       \n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout),\n",
    "            # nn.Linear(seq_len, 2),\n",
    "        )\n",
    "        return emb_cnn\n",
    "    \n",
    "    def remove_pend_tokens_1d(self, tokens, seqs):\n",
    "        padding_masks = tokens.ne(self.alphabet.padding_idx)\n",
    "\n",
    "        # remove eos token  （suffix first）\n",
    "        if self.alphabet.append_eos:     # default is right\n",
    "            eos_masks = tokens.ne(self.alphabet.eos_idx)\n",
    "            eos_pad_masks = (eos_masks & padding_masks).to(seqs)\n",
    "            seqs = seqs * eos_pad_masks.unsqueeze(-1)\n",
    "            seqs = seqs[:, ..., :-1, :]\n",
    "            padding_masks = padding_masks[:, ..., :-1]\n",
    "\n",
    "        # remove bos token\n",
    "        if self.alphabet.prepend_bos:    # default is left\n",
    "            seqs = seqs[:, ..., 1:, :]\n",
    "            padding_masks = padding_masks[:, ..., 1:]\n",
    "\n",
    "        if not padding_masks.any():\n",
    "            padding_masks = None\n",
    "\n",
    "        return seqs, padding_masks\n",
    "    \n",
    "class Shape_Encoder(nn.Module):\n",
    "    def __init__(self, seq_len, dim, **kwargs):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        # self.pos_enc = SinusoidalPosEmb(dim=dim).to(device)\n",
    "        self.pos_enc = ShapeEmb(dim=dim).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.unsqueeze(0)\n",
    "        pos = torch.arange(self.seq_len, device=x.device).unsqueeze(0)\n",
    "        pos = self.pos_enc(pos).unsqueeze(0)\n",
    "        # print(\"x shape:\", x.shape)\n",
    "        # print(\"pos shape:\", pos.shape)\n",
    "\n",
    "        x = x.unsqueeze(2)\n",
    "        pos = pos.unsqueeze(1)\n",
    "\n",
    "        # print(\"x shape:\", x.shape)\n",
    "        # print(\"pos shape:\", pos.shape)\n",
    "        x = x + pos\n",
    "        # print(\"x2 shape:\", x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Pos_Encoder(nn.Module):\n",
    "    def __init__(self, seq_len, dim, **kwargs):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pos_enc = SinusoidalPosEmb(dim=dim).to(device)\n",
    "        # self.pos_enc = ShapeEmb(dim=dim).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # x = x.unsqueeze(0)\n",
    "        pos = torch.arange(self.seq_len, device=x.device).unsqueeze(0)\n",
    "        pos = self.pos_enc(pos)\n",
    "        # print(\"x shape:\", x.shape)\n",
    "        # print(\"pos shape:\", pos.shape)\n",
    "\n",
    "        # x = x.unsqueeze(2)\n",
    "        # pos = pos.unsqueeze(1)\n",
    "\n",
    "        # print(\"x shape:\", x.shape)\n",
    "        # print(\"pos shape:\", pos.shape)\n",
    "        x = x + pos\n",
    "        # print(\"x2 shape:\", x.shape)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        stride=1,\n",
    "        dilation=1,\n",
    "        conv_layer=nn.Conv1d,\n",
    "        norm_layer=nn.BatchNorm1d,\n",
    "    ):\n",
    "        super(ResBlock, self).__init__()        \n",
    "        self.bn1 = norm_layer(in_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = conv_layer(in_channels, out_channels, kernel_size=3, stride=stride, padding=dilation, bias=False)       \n",
    "        self.bn2 = norm_layer(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv_layer(out_channels, out_channels, kernel_size=3, padding=dilation, bias=False)\n",
    "\n",
    "        if stride > 1 or out_channels != in_channels: \n",
    "            self.downsample = nn.Sequential(\n",
    "                conv_layer(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                norm_layer(out_channels),\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = None\n",
    "            \n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv1(out)        \n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight, std=0.001)\n",
    "        if isinstance(m.bias, nn.Parameter):\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "    elif classname.find('Conv') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        if m.affine:\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "            nn.init.constant_(m.bias, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create utr_func_predictor sucessfully\n",
      "Human5PrimeUTRPredictor(\n",
      "  (reductio_module): Linear(in_features=640, out_features=512, bias=True)\n",
      "  (RNA_embed): RNA_embedding_model(\n",
      "    (transformer1): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (activation): GELU(approximate='none')\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (backbone): RNABertModel(\n",
      "    (embed_tokens): Embedding(25, 640, padding_idx=1)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x TransformerLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (k_proj): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (v_proj): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (q_proj): Linear(in_features=640, out_features=640, bias=True)\n",
      "          (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=640, out_features=5120, bias=True)\n",
      "        (fc2): Linear(in_features=5120, out_features=640, bias=True)\n",
      "        (final_layer_norm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (contact_head): ContactPredictionHead(\n",
      "      (regression): Linear(in_features=240, out_features=1, bias=True)\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "    (embed_positions): LearnedPositionalEmbedding(1026, 640, padding_idx=1)\n",
      "    (emb_layer_norm_before): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    (emb_layer_norm_after): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    (lm_head): RobertaLMHead(\n",
      "      (dense): Linear(in_features=640, out_features=640, bias=True)\n",
      "      (layer_norm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pos_out): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      "  (pos_enc): Pos_emb(\n",
      "    (position_embeddings): Embedding(512, 512)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "task=\"rgs\"\n",
    "arch=\"cnn\"\n",
    "input_items = [\"emb-rnafm\"]   # [\"seq\"], [\"emb-rnafm\"]\n",
    "model_name = arch.upper() + \"_\" + \"_\".join(input_items) \n",
    "utr_func_predictor = Human5PrimeUTRPredictor(\n",
    "    alphabet, task=task, arch=arch, input_types=input_items    \n",
    ")\n",
    "utr_func_predictor.apply(weights_init)\n",
    "utr_func_predictor.to(device)\n",
    "print(\"create utr_func_predictor sucessfully\")\n",
    "print(utr_func_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "---Loaded---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNA_Model(\n",
       "  (emb): Embedding(4, 512)\n",
       "  (BERTmodel): Load_RNABert_Model(\n",
       "    (model): BertForMaskedLM(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(6, 120, padding_idx=0)\n",
       "          (position_embeddings): Embedding(440, 120)\n",
       "          (token_type_embeddings): Embedding(2, 120)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (selfattn): BertSelfAttention(\n",
       "                  (query): Linear(in_features=120, out_features=120, bias=True)\n",
       "                  (key): Linear(in_features=120, out_features=120, bias=True)\n",
       "                  (value): Linear(in_features=120, out_features=120, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=120, out_features=120, bias=True)\n",
       "                  (LayerNorm): BertLayerNorm()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=120, out_features=40, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=40, out_features=120, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=120, out_features=120, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (cls): BertPreTrainingHeads(\n",
       "        (predictions): MaskedWordPredictions(\n",
       "          (transform): BertPredictionHeadTransform(\n",
       "            (dense): Linear(in_features=120, out_features=120, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "          )\n",
       "          (decoder): Linear(in_features=120, out_features=6, bias=False)\n",
       "        )\n",
       "        (predictions_ss): MaskedWordPredictions(\n",
       "          (transform): BertPredictionHeadTransform(\n",
       "            (dense): Linear(in_features=120, out_features=120, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "          )\n",
       "          (decoder): Linear(in_features=120, out_features=8, bias=False)\n",
       "        )\n",
       "        (seq_relationship): Linear(in_features=120, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pos_enc): Pos_emb(\n",
       "    (position_embeddings): Embedding(512, 512)\n",
       "  )\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNA_Model()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Metric\n",
    "The metric accumulates all predictions and then performs average to be consistent with the competition metric. However, the difference with a simple batch-based average is negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(pred,target):\n",
    "\n",
    "    p = pred[:,:pred.shape[1]].squeeze(1)\n",
    "    seq_len = p.size(1)\n",
    "    y = target['react'][:,:seq_len].clip(0,1)\n",
    "    # print('p',p.shape)\n",
    "    # print('y',y.shape)\n",
    "    loss = F.l1_loss(p, y, reduction='none')\n",
    "    loss = loss[~torch.isnan(loss)].mean()\n",
    "#     print('--------',loss,'---------')\n",
    "    return loss\n",
    "\n",
    "class MAE(Metric):\n",
    "    def __init__(self): \n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self): \n",
    "        self.x,self.y = [],[]\n",
    "        \n",
    "    def accumulate(self, learn):\n",
    "        x = learn.pred.squeeze(1)\n",
    "        y = learn.y['react'][:,:x.size(1)].clip(0, 1)\n",
    "        x = x.reshape(-1, 2)\n",
    "        y = y.reshape(-1, 2)\n",
    "        # print(x.shape)\n",
    "        # print(y.shape)\n",
    "        self.x.append(x)\n",
    "        self.y.append(y)\n",
    "    @property\n",
    "    def value(self):\n",
    "        # print(self.x)\n",
    "        x = torch.cat(self.x,dim = 0)\n",
    "        y = torch.cat(self.y,dim = 0)\n",
    "        # print(x.shape)\n",
    "        # print(y.shape)\n",
    "        \n",
    "        loss = F.l1_loss(x, y, reduction='none')\n",
    "        loss = loss[~torch.isnan(loss)].mean()\n",
    "        print('----',loss,'----')\n",
    "        with open('log.txt', 'a+') as file:\n",
    "            file.write(f'Loss: {loss}\\n')\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "class PrintMetricsCallback(Callback):\n",
    "    def after_epoch(self):\n",
    "        print(f\"Epoch: {self.learn.epoch}, Training loss: {self.learn.recorder.losses[-1]}, Validation loss: {self.learn.recorder.values[-1][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "df = pd.read_parquet(os.path.join(PATH,'train_data.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'seq': tensor([2, 2, 2, 0, 0, 1, 2, 0, 1, 3, 1, 2, 0, 2, 3, 0, 2, 0, 2, 3, 1, 2, 0, 0,\n",
    "#          0, 0, 0, 1, 2, 0, 3, 2, 0, 3, 0, 3, 2, 2, 0, 3, 3, 3, 0, 1, 3, 1, 1, 2,\n",
    "#          0, 2, 2, 0, 2, 0, 1, 2, 0, 0, 1, 3, 0, 1, 1, 0, 1, 2, 0, 0, 1, 0, 2, 2,\n",
    "#          2, 2, 0, 0, 0, 1, 3, 1, 3, 0, 1, 1, 1, 2, 3, 2, 2, 1, 2, 3, 1, 3, 1, 1,\n",
    "#          2, 3, 3, 3, 2, 0, 1, 2, 0, 2, 3, 0, 0, 2, 3, 1, 1, 3, 0, 0, 2, 3, 1, 0,\n",
    "#          0, 1, 0, 3, 2, 1, 0, 3, 2, 1, 0, 3, 2, 1, 2, 2, 1, 3, 3, 1, 2, 2, 1, 1,\n",
    "#          2, 1, 0, 3, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
    "#          0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "#          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
    "#  'tokens': tensor([[6, 6, 6, 4, 4, 5, 6, 4, 5, 7, 5, 6, 4, 6, 7, 4, 6, 4, 6, 7, 5, 6, 4, 4,\n",
    "#           4, 4, 4, 5, 6, 4, 7, 6, 4, 7, 4, 7, 6, 6, 4, 7, 7, 7, 4, 5, 7, 5, 5, 6,\n",
    "#           4, 6, 6, 4, 6, 4, 5, 6, 4, 4, 5, 7, 4, 5, 5, 4, 5, 6, 4, 4, 5, 4, 6, 6,\n",
    "#           6, 6, 4, 4, 4, 5, 7, 5, 7, 4, 5, 5, 5, 6, 7, 6, 6, 5, 6, 7, 5, 7, 5, 5,\n",
    "#           6, 7, 7, 7, 6, 4, 5, 6, 4, 6, 7, 4, 4, 6, 7, 5, 5, 7, 4, 4, 6, 7, 5, 4,\n",
    "#           4, 5, 4, 7, 6, 5, 4, 7, 6, 5, 4, 7, 6, 5, 6, 6, 5, 7, 7, 5, 6, 6, 5, 5,\n",
    "#           6, 5, 4, 7, 6, 4, 4, 4, 4, 6, 4, 4, 4, 5, 4, 4, 5, 4, 4, 5, 4, 4, 5, 4,\n",
    "#           4, 5]]),\n",
    "#  'fm_embed': tensor([[[-0.0611,  0.1168,  0.0513,  ...,  0.0102, -0.0466, -0.0495],\n",
    "#           [ 0.1240, -0.1895,  0.0813,  ..., -0.3088,  0.1768, -0.0184],\n",
    "#           [ 0.1964, -0.2130,  0.1875,  ..., -0.2599,  0.0222, -0.1515],\n",
    "#           ...,\n",
    "#           [ 0.1636,  0.0329,  0.2152,  ..., -0.1018,  0.1041, -0.0279],\n",
    "#           [ 0.1615, -0.0473,  0.1812,  ..., -0.0754,  0.1097, -0.1988],\n",
    "#           [-0.1284,  0.0399, -0.0071,  ..., -0.1088,  0.2529, -0.2890]]]),\n",
    "#  'mask': tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "#          False, False, False, False, False, False, False, False, False, False,\n",
    "#          False, False, False, False, False, False, False, False, False, False,\n",
    "#          False, False, False, False, False, False, False, False, False, False,\n",
    "#          False, False, False, False, False, False])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "---Loaded---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.00% [1/100 08:15&lt;13:37:36]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.227002</td>\n",
       "      <td>0.227577</td>\n",
       "      <td>0.227872</td>\n",
       "      <td>08:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='1115' class='' max='2127' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      52.42% [1115/2127 03:35&lt;03:15 0.2278]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- tensor(0.2279, device='cuda:0') ----\n"
     ]
    }
   ],
   "source": [
    "for fold in [0]: # running multiple folds at kaggle may cause OOM\n",
    "#     df_sample = df.sample(frac=0.2)  # 选择数据的子集\n",
    "\n",
    "    ds_train = RNA_Dataset(df, mode='train', fold=fold, nfolds=nfolds)\n",
    "    ds_train_len = RNA_Dataset(df, mode='train', fold=fold, \n",
    "                nfolds=nfolds, mask_only=True)\n",
    "    sampler_train = torch.utils.data.RandomSampler(ds_train_len)\n",
    "    len_sampler_train = LenMatchBatchSampler(sampler_train, batch_size=bs,\n",
    "                drop_last=True)\n",
    "    dl_train = DeviceDataLoader(torch.utils.data.DataLoader(ds_train, \n",
    "                batch_sampler=len_sampler_train, num_workers=num_workers,\n",
    "                persistent_workers=True), device)\n",
    "\n",
    "    ds_val = RNA_Dataset(df, mode='eval', fold=fold, nfolds=nfolds)\n",
    "    ds_val_len = RNA_Dataset(df, mode='eval', fold=fold, nfolds=nfolds, \n",
    "               mask_only=True)\n",
    "    sampler_val = torch.utils.data.SequentialSampler(ds_val_len)\n",
    "    len_sampler_val = LenMatchBatchSampler(sampler_val, batch_size=bs, \n",
    "               drop_last=False) \n",
    "    dl_val= DeviceDataLoader(torch.utils.data.DataLoader(ds_val, \n",
    "               batch_sampler=len_sampler_val, num_workers=num_workers), device)\n",
    "    gc.collect()\n",
    "\n",
    "    data = DataLoaders(dl_train,dl_val)\n",
    "    model = RNA_Model()   \n",
    "    model = model.to(device)\n",
    "\n",
    "    # task=\"rgs\"\n",
    "    # arch=\"cnn\"\n",
    "    # input_items = [\"emb-rnafm\"]   # [\"seq\"], [\"emb-rnafm\"]\n",
    "    # model_name = arch.upper() + \"_\" + \"_\".join(input_items) \n",
    "    # utr_func_predictor = Human5PrimeUTRPredictor(\n",
    "    #     alphabet, task=task, arch=arch, input_types=input_items    \n",
    "    # )\n",
    "    # utr_func_predictor.apply(weights_init)\n",
    "    # utr_func_predictor.to(device)\n",
    "    # print(\"create utr_func_predictor sucessfully\")\n",
    "\n",
    "    learn = Learner(data, utr_func_predictor, loss_func=loss,cbs=[GradientClip(3.0)],\n",
    "                metrics=[MAE()]).to_fp16() \n",
    "    #fp16 doesn't help at P100 but gives x1.6-1.8 speedup at modern hardware\n",
    "\n",
    "    learn.fit_one_cycle(100, lr_max=5e-4, wd=0.05, pct_start=0.02)\n",
    "    torch.save(learn.model.state_dict(),os.path.join(OUT,f'{fname}_{fold}.pth'))\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
